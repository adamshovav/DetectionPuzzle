{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Data exploration and processing\n",
    "-  Build toy models and train on local env\n",
    "-  Training and hyperparameter tuning on AWS Sagemaker\n",
    "-  Save the model and write inference script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details in terms of data analysis, processing, and architecture choice, please see Selected_Architecture document. \n",
    "\n",
    "Data inspection: \n",
    "\n",
    "\t-Image rotation is less than +/- 3 degrees\n",
    "\t-Image scaling is less than +/- 3% on both axes\n",
    "\t-Image capture offsets are less than +/- 60 px (off the image average) on both axes\n",
    "\n",
    "Small dataset in danger of overfitting. Dropout layer and data augmentation should help there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build toy models and train on local env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  A very basic CNN should be good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "withDropout = False\n",
    "conv2D_1 = 32\n",
    "conv2D_2 = 32\n",
    "conv2D_3 = 0\n",
    "dense_1 = 10\n",
    "dense_2 = 10\n",
    "dense_3 = 0\n",
    "\n",
    "def SimpleCNN(withDropout=withDropout):\n",
    "    \"\"\"\n",
    "    WithDropout: If True, then dropout regularlization is added.\n",
    "    This feature is experimented later.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(conv2D_1, (3, 3), input_shape = (HEIGHT, WIDTH, 1)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "    if conv2D_2 > 0:\n",
    "        model.add(Conv2D(conv2D_2,(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        if withDropout:\n",
    "            model.add(Dropout(0.1))\n",
    "    \n",
    "    if conv2D_3 > 0:\n",
    "        model.add(Conv2D(conv2D_3,(2,2)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        if withDropout:\n",
    "            model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(dense_1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "    \n",
    "    if dense_2 > 0:\n",
    "        model.add(Dense(dense_2))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        if withDropout:\n",
    "            model.add(Dropout(0.1))\n",
    "    \n",
    "    if dense_3 > 0:\n",
    "        model.add(Dense(dense_3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        if withDropout:\n",
    "            model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(6))\n",
    "    sgd = SGD(lr=0.01, momentum = 0.9, nesterov=True)\n",
    "    if gpu_count > 1:\n",
    "        parallel_model = multi_gpu_model(model, gpus=gpu_count)\n",
    "    else:\n",
    "        parallel_model = model\n",
    "    parallel_model.compile(loss=\"mean_squared_error\", optimizer=sgd)\n",
    "    \n",
    "    return parallel_model, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  The CNN with just 120 images to train (20% is for test) overfits. The loss for training set is a lot higher than the loss for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Shifting pictures randomly at every batch created more training data seems sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 688\n",
    "WIDTH = 1032\n",
    "\n",
    "class DataModifier(object):\n",
    "    def fit(self,X_,y_):\n",
    "        return(NotImplementedError)\n",
    "\n",
    "class ShiftPic(DataModifier):\n",
    "    def __init__(self, prop=0.1):\n",
    "        self.prop = prop\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = self.shift_image(X , y, prop=self.prop)\n",
    "        return X, y\n",
    "\n",
    "    def random_shift(self, shift_range, n=None):\n",
    "        \"\"\"\n",
    "        :param shift_range:\n",
    "        The maximum number of columns/rows to shift\n",
    "        :return:\n",
    "        keep(0):   minimum row/column index to keep\n",
    "        keep(1):   maximum row/column index to keep\n",
    "        assign(0): minimum row/column index to assign\n",
    "        assign(1): maximum row/column index to assign\n",
    "        shift:     amount to shift the keypoint\n",
    "\n",
    "        assign(1) - assign(0) == keep(1) - keep(0)\n",
    "        \"\"\"\n",
    "        shift = np.random.randint(-shift_range, shift_range)\n",
    "\n",
    "        def shift_left(n, shift):\n",
    "            shift = np.abs(shift)\n",
    "            return (0, n - shift)\n",
    "        \n",
    "        def shift_right(n, shift):\n",
    "            shift = np.abs(shift)\n",
    "            return (shift, n)\n",
    "\n",
    "        if shift < 0:\n",
    "            keep = shift_left(n, shift)\n",
    "            assign = shift_right(n, shift)\n",
    "        else:\n",
    "            assign = shift_left(n, shift)\n",
    "            keep = shift_right(n, shift)\n",
    "\n",
    "        return keep, assign, shift\n",
    "\n",
    "    def shift_single_image(self, x_, y_, prop=0.1):\n",
    "        \"\"\"\n",
    "        :param x_: a single picture array (HEIGHT, WIDTH, 1)\n",
    "        :param y_: keypoint locations flatten (1, 6)\n",
    "                    [0::2] contains x axis values\n",
    "                    [1::2] contains y axis values\n",
    "        :param prop: proportion of random horizontal and vertical shift\n",
    "                        relative to the number of columns\n",
    "                        e.g. prop = 0.1 then the picture is moved at least by\n",
    "                        0.1*1032 = 103 columns/rows\n",
    "        :return:\n",
    "        x_, y_\n",
    "        \"\"\"\n",
    "        w_shift_max = int(x_.shape[0] * prop)\n",
    "        h_shift_max = int(x_.shape[1] * prop)\n",
    "\n",
    "        w_keep, w_assign, w_shift = self.random_shift(w_shift_max, HEIGHT)\n",
    "        h_keep, h_assign, h_shift = self.random_shift(h_shift_max, WIDTH)\n",
    "\n",
    "        x_[w_assign[0]:w_assign[1],\n",
    "            h_assign[0]:h_assign[1], :] = x_[w_keep[0]:w_keep[1],\n",
    "                                            h_keep[0]:h_keep[1], :]\n",
    "\n",
    "        y_[:, 0::2] = y_[:, 0::2] - h_shift/float(x_.shape[0]/2.)\n",
    "        y_[:, 1::2] = y_[:, 1::2] - w_shift/float(x_.shape[1]/2.)\n",
    "\n",
    "        return x_, y_\n",
    "\n",
    "    def shift_image(self, X, y, prop=0.1):\n",
    "        for irow in range(X.shape[0]):\n",
    "            x_ = X[irow]\n",
    "            y_ = y[irow].reshape((1, 6))\n",
    "            X[irow], y[irow] = self.shift_single_image(x_, y_, prop=prop)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and hyperparameter tuning on Amazon Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Train the CNN with augmented data using Amazon Sagemaker\n",
    "-  Trained in under 5 minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "                       image_name=image_name,\n",
    "                       base_job_name=base_job_name,\n",
    "                       role=role, \n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type='ml.p3.8xlarge',\n",
    "                       output_path=output_path,\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "estimator.set_hyperparameters(epochs=290, gpu_count=4, batch_size=32, conv2D_3=0, dense_3=0)\n",
    "\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter\n",
    "\n",
    "hyperparameter_ranges = {'conv2D_1': IntegerParameter(16, 64), 'conv2D_2': IntegerParameter(16, 64), 'dense_1': IntegerParameter(10, 30), 'dense_2': IntegerParameter(10, 30)}\n",
    "objective_metric_name = 'score'\n",
    "metric_definitions = [{'Name': 'score', 'Regex': 'score: ([0-9\\\\.]+)'}]\n",
    "\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                        objective_metric_name,\n",
    "                        hyperparameter_ranges,\n",
    "                        metric_definitions,\n",
    "                        max_jobs=8,\n",
    "                        max_parallel_jobs=2)\n",
    "\n",
    "tuner.fit({'training': train_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv2D_2': '32', 'dense_2': '20', 'batch_size': '32', 'conv2D_1': '32', 'conv2D_3': '0', 'epochs': '300', 'gpu_count': '4', 'dense_3': '0', 'dense_1': '20'}\n",
      "{'training_loss': 0.00033, 'eval_loss': 0.00046}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "conv2D_1, conv2D_2, conv2D_3, dense_1, dense_2, dense_3 are parameters of the CNN\n",
    "\"\"\" \n",
    "# Best hyperparameters:\n",
    "\n",
    "print({'conv2D_2': '32', 'dense_2': '20', 'batch_size': '32', 'conv2D_1': '32', 'conv2D_3': '0', 'epochs': '300', \n",
    " 'gpu_count': '4', 'dense_3': '0', 'dense_1': '20'})\n",
    "\n",
    "print({\n",
    "    \"training_loss\": 0.00033,\n",
    "    \"eval_loss\": 0.00046\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
